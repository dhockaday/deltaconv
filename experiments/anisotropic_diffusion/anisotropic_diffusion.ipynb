{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perona-Malik anisotropic diffusion\n",
    "\n",
    "Experiments to validate anisotropy in DeltaConv and compare to other intrinsic convolutions.\n",
    "This notebook outputs the figures as shown in the paper in Figure 2 of the main paper and Figure 2, 3 of the supplement.\n",
    "\n",
    "First, we need to install a couple of libraries that are only required for this notebook and not for the rest of the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kornia matplotlib scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import kornia as K\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and show some of the sample images provided by the Scikit Image toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convenience function to plot images\n",
    "def imshow(input: torch.Tensor, ax=None, outline=True):\n",
    "    \"\"\"Shows one image given as a torch Tensor.\n",
    "    \n",
    "    Args:\n",
    "        input (Tensor): the image to be shown.\n",
    "        ax (axis, optional): if provided, will plot the image in the given axis (default: None).\n",
    "        outline (bool, optional): if set to true, will show an outline around the image (default: True).\n",
    "        \"\"\"\n",
    "    out = torchvision.utils.make_grid(input, nrow=2, padding=5)\n",
    "    out_np: np.ndarray = K.utils.tensor_to_image(out)\n",
    "    if ax: \n",
    "        ax.imshow((out_np.clip(0, 1) * 255).astype(np.uint8))\n",
    "        if outline:\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    else:\n",
    "        plt.imshow((out_np.clip(0, 1) * 255).astype(np.uint8))\n",
    "        if outline:\n",
    "            ax = plt.gca()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "        else:\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Load images into a dictionary for ease of access\n",
    "images = {}\n",
    "images['astronaut'] = K.utils.image_to_tensor(rescale(color.rgb2gray(data.astronaut()), 0.5)).float()[None]\n",
    "images['camera'] = K.utils.image_to_tensor(rescale(data.camera(), 0.5)).float()[None]\n",
    "\n",
    "# And show the images\n",
    "imshow(images['astronaut'])\n",
    "imshow(images['camera'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anisotropic Diffusion\n",
    "\n",
    "Next, we create an anisotropic diffusion function that explicitly computes anisotropic diffusion for one timestep.\n",
    "\n",
    "This implementation follows the anisotropic diffusion equation [described by Pietro Perona and Jitendra Malik](https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf) (equation 3).\n",
    "Both non-linearities described in the Perona-Malik paper are implemented and can be selected with the `c_func` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anisotropic_diffusion(image, kappa=0.05, c_func='exp'):\n",
    "    \"\"\"Applies one step of anisotropic diffusion.\n",
    "    The parameter K and c_func parameters influence the non-linearity applied to the gradient norms.\n",
    "    \"\"\"\n",
    "    # Compute the gradient\n",
    "    grads = K.filters.spatial_gradient(image, order=1)\n",
    "    grads_x = grads[:, :, 0]\n",
    "    grads_y = grads[:, :, 1]\n",
    "\n",
    "    # Apply a non-linearity to the norm of the gradient\n",
    "    grad_norm = np.sqrt(grads_x ** 2 + grads_y ** 2)\n",
    "    if c_func == 'exp':\n",
    "        c = np.exp(-(grad_norm / kappa) ** 2)\n",
    "    else:\n",
    "        c = 1 / (1 + grad_norm / kappa) ** 2\n",
    "\n",
    "    # Scale the gradient with the non-linearity\n",
    "    grads_x = c * grads_x\n",
    "    grads_y = c * grads_y\n",
    "\n",
    "    # Apply divergence\n",
    "    div = (\n",
    "        K.filters.spatial_gradient(grads_x, order=1)[:, :, 0]\n",
    "        + K.filters.spatial_gradient(grads_y, order=1)[:, :, 1]\n",
    "    )\n",
    "    return image + div\n",
    "\n",
    "def anisotropic_diffusion_nsteps(image, n):\n",
    "    \"\"\"Applies anisotropic diffusion on an input image for n steps.\"\"\"\n",
    "    im_blurred = image\n",
    "    for i in range(n):\n",
    "        im_blurred = anisotropic_diffusion(im_blurred, kappa=0.05, c_func='exp')\n",
    "    return im_blurred\n",
    "\n",
    "# Test on a sample image with a very large number of timesteps\n",
    "im_anisotropic_astronaut = anisotropic_diffusion_nsteps(images['astronaut'], 100)\n",
    "im_anisotropic_camera = anisotropic_diffusion_nsteps(images['camera'], 100)\n",
    "imshow(im_anisotropic_astronaut)\n",
    "imshow(im_anisotropic_camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution operators and architecture\n",
    "\n",
    "Create all the networks to be tested: CNNs, DeltaNet, DiffusionNet, DGCNN, PointNet++, GCN.\n",
    "\n",
    "We reimplemented seven graph/surface/point cloud convolution operators to work on images.\n",
    "The architecture is a ResNet with `num_layers` depth, and `out_channels` width.\n",
    "\n",
    "Please see the file `architectures.py` for the reimplementation of each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the networks\n",
    "\n",
    "We train each network for 200 iterations and inspect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 200\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Network settings\n",
    "num_layers = 16     # Depth of the network\n",
    "out_channels = 16   # Width of the network in hidden layers\n",
    "in_channels = 1     # Number of input channels (we're working on grayscale images)\n",
    "\n",
    "# Device to train on\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Network configurations\n",
    "def config(net, num_layers, out_channels, in_channels, device=torch.device('cuda'), optimizer=torch.optim.Adam, lr=1e-3, scheduler=torch.optim.lr_scheduler.StepLR, loss=torch.nn.L1Loss):\n",
    "    config = {'net': net(num_layers, out_channels, in_channels).to(device)}\n",
    "    config['optimizer'] = optimizer(config['net'].parameters(), lr=lr, weight_decay=1e-5)\n",
    "    config['scheduler'] = scheduler(config['optimizer'], step_size=50)\n",
    "    config['loss_func'] = loss()\n",
    "    return config\n",
    "\n",
    "# Load the networks to be trained\n",
    "nets = [DeltaNet, EdgeNet, PointNet, GCN, DiffusionNet, ConvNet]\n",
    "\n",
    "# Train the networks\n",
    "def train(nets, input, target):\n",
    "\n",
    "    input = input.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    pred_images = []\n",
    "    for net in nets:\n",
    "        c = config(net, num_layers, out_channels, in_channels, device)\n",
    "        c['net'].train()\n",
    "        for _ in range(iterations):\n",
    "            c['optimizer'].zero_grad()\n",
    "            pred = c['net'](input)\n",
    "            loss = c['loss_func'](pred, target)\n",
    "            loss.backward()\n",
    "            c['optimizer'].step()\n",
    "            c['scheduler'].step()\n",
    "\n",
    "        c['net'].eval()\n",
    "        pred_images.append(c['net'](input.to(device)).detach().to('cpu'))\n",
    "    return pred_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "\n",
    "Finally, it's time to train the network on a given number of timesteps and show the results.\n",
    "These figures correspond to Figure 2 in the main paper and Figure 2 in the supplement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: set fonts to linux libertine to exactly match the figures in the paper.\n",
    "# import matplotlib.font_manager as font_manager\n",
    "# from matplotlib.font_manager import _rebuild; _rebuild()\n",
    "# # Set path to the directory where you have installed the font.\n",
    "# fontpath = '/usr/share/fonts/opentype/linux-libertine/LinBiolinum_R.otf'\n",
    "# prop = font_manager.FontProperties(fname=fontpath)\n",
    "# plt.rcParams[\"font.family\"] = prop.get_name()\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "\n",
    "def single_n(input, n=50):\n",
    "    \"\"\"Sets up a training sample from an input image\n",
    "    and a given number of timesteps for anisotropic diffusion, n\n",
    "    then trains each of the networks on the input-target pair.\n",
    "    \"\"\"\n",
    "    # Compute the target image.\n",
    "    target = anisotropic_diffusion_nsteps(input, n)\n",
    "    # Train each network on the input-target pair.\n",
    "    out = train(nets, input, target)\n",
    "\n",
    "    # Plot the outputs in a 2-row grid.\n",
    "    n_output = len(out)\n",
    "    n_rows = 2\n",
    "    n_cols = (2 + n_output) // n_rows\n",
    "\n",
    "    # Create the subplots\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "    fig.set_size_inches((2 + n_output) * 6, 10)\n",
    "    imshow(input.to('cpu'), ax[0][0])\n",
    "    ax[0][0].set_title('Input')\n",
    "    imshow(target.to('cpu'), ax[0][1])\n",
    "    ax[0][1].set_title('Target')\n",
    "\n",
    "    for i, pred_image in enumerate(out):\n",
    "        idx = 2 + i\n",
    "        row, col = idx // n_cols, idx % n_cols\n",
    "        imshow(pred_image, ax[row][col])\n",
    "        ax[row][col].set_title(nets[i].name())\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=-0.85)\n",
    "    plt.show()\n",
    "\n",
    "# Run the experiment on the camera input image and 20 anisotropic diffusion steps.\n",
    "# Figure 2 of the main paper.\n",
    "single_n(images['astronaut'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment on the astronaut input image and 20 anisotropic diffusion steps.\n",
    "# Figure 2 of the supplement.\n",
    "single_n(images['camera'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning diffusion times\n",
    "\n",
    "Next, we experiment with the ability of DeltaConv to optimize to specific diffusion times.\n",
    "We generate a set of target images and optimize for each.\n",
    "\n",
    "The output of this experiment is seen in Figure 3 in the supplement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_n(input, ns=[1, 5, 10, 20, 40]):\n",
    "    \"\"\"Set up a target image for each of the diffusion times given in ns\n",
    "    and train DeltaNet on the input-target pair.\n",
    "    \"\"\"\n",
    "    out_list = []\n",
    "    target_list = []\n",
    "    for n in ns:\n",
    "        target = anisotropic_diffusion_nsteps(input, n)\n",
    "        target_list.append(target)\n",
    "        out_list.append(train([DeltaNet], input, target))\n",
    "\n",
    "    n_output = len(out_list[0])\n",
    "    n_rows = n_output + 1\n",
    "    n_cols = len(ns)\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "    fig.set_size_inches(6 * n_cols, 6 * n_rows)\n",
    "\n",
    "    for i, n in enumerate(ns):\n",
    "        imshow(target_list[i].detach().to('cpu'), ax[0][i])\n",
    "        ax[0][i].set_title('Target {} steps'.format(n))\n",
    "\n",
    "        for j, pred_image in enumerate(out_list[i]):\n",
    "            imshow(pred_image, ax[j + 1][i])\n",
    "            ax[j + 1][i].set_title('{} {} step{}'.format(nets[j].name(), n, 's' if n > 1 else ''))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Figure 3 of the supplement\n",
    "multiple_n(images['astronaut'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "192bf5d98c0b14158742edb2fac44c507798bedb6bc4c35ffaa134705499d91c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deltaconv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
